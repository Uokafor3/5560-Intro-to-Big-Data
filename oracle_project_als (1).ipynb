{"cells":[{"cell_type":"markdown","source":["## CIS5560: PySpark Collaborative Filtering in Databricks\n\n### by Team 4 (Uche, Raymond, Tofunmi and Sweta) edited on 05/15/2020\nTested in Runtime 6.5 (Spark 2.4.5/2.4.0 Scala 2.11) of Databricks CE"],"metadata":{}},{"cell_type":"markdown","source":["## Collaborative Filtering\nCollaborative filtering is a machine learning technique that predicts ratings awarded to items by users.\n\nImport the ALS class\nIn this exercise, we used the Alternating Least Squares collaborative filtering algorithm to creater a recommender."],"metadata":{}},{"cell_type":"markdown","source":["## Steps to download dataset and do some data engineering (Cleaning up dataset) before importing into databricks\n\nall dataset engineering were done in Jupyter Notebook before importing into databricks\n\ndataset link: https://www.kaggle.com/darshank2019/review#yelp_academic_dataset_review.csv\n\ndownload dataset and using a Jupyter Notebook(we used google colab), we accessed the dataset with total rows = 6685900\n\nwe took a slice of the full dataset of the first 1500000 rows and used that as our full dataset.\n\nwe removed the inverted commas and the letter \"b\" present in all rows (data cleaning)\n\nwe converted the alphanumeric values in the user_id, review_id, & business_id to numeric values\n\nwe tried to drop rows wit missing values and counted the total number of rows again and it was still 1500000.\n\nwe created a subset of our cleaned dataset named df_ml_csv with 120000 rows which we used for both Azure ML & Databricks\n\nNOTE: the .py & .ipynb files containing all codes used for data engineering and analysis is included in the total submission package and is availble in our github link"],"metadata":{}},{"cell_type":"markdown","source":["Import the df_ml.csv dataset"],"metadata":{}},{"cell_type":"markdown","source":["##Prepare the Data\nFirst, import the libraries you will need and prepare the training and test data:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\nfrom pyspark.sql.types import StructField, StringType, IntegerType, StructType"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["## Create a DataFrame Schema, \nthat should be a Table schema"],"metadata":{}},{"cell_type":"code","source":["# DataFrame Schema, that should be a Table schema by Team 4 \ndf_mlSchema = StructType([\n  StructField(\"user_id\", IntegerType(), False),\n  StructField(\"text\", StringType(), False),\n  StructField(\"date\", TimestampType(), False),\n  StructField(\"review_id\", IntegerType(), False),\n  StructField(\"business_id\", IntegerType(), False),\n  StructField(\"funny\", IntegerType(), False),\n  StructField(\"cool\", IntegerType(), False),\n  StructField(\"useful\", IntegerType(), False),\n  StructField(\"stars\", IntegerType(), False),\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["%fs ls /FileStore/tables/df_ml.csv"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/df_ml.csv</td><td>df_ml.csv</td><td>77730282</td></tr></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"code","source":["IS_SPARK_SUBMIT_CLI = False\nif IS_SPARK_SUBMIT_CLI:\n    sc = SparkContext.getOrCreate()\n    spark = SparkSession(sc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["##Load Dataset \n\nensure command line above: IS_SPARK_SUBMIT_CLI = False. Also remember to set it to 'True' before exporting"],"metadata":{}},{"cell_type":"markdown","source":["Read csv file from DBFS (Databricks File Systems)\n\n## follow the direction to read your table after upload it to Data at the left frame\nNOTE: See above for the data type - \n\nAfter df_ml_csv file is added to the data of the left frame, create a table using the UI, especially, \"Upload File\"\ntick header and infer schema before creating table"],"metadata":{}},{"cell_type":"code","source":["if IS_SPARK_SUBMIT_CLI:\n   df_ml = spark.read.csv('df_ml.csv', inferSchema=True, header=True)\nelse:\n    df_ml = spark.sql(\"SELECT * FROM df_ml_csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["df_ml.na.drop()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: DataFrame[_c0: int, user_id: int, text: string, date: timestamp, review_id: int, business_id: int, funny: int, cool: int, useful: int, stars: double]</div>"]}}],"execution_count":14},{"cell_type":"code","source":["df_ml.select(\"review_id\").distinct().count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: 120000</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["## the label column, stars is conditioned as follows:  \nstars (stars > 2 = 1 (positive review) else: 0 (negative review)"],"metadata":{}},{"cell_type":"code","source":["df_ml = df_ml.select(\"user_id\", \"business_id\", ((col(\"stars\") > 2).cast(\"Double\").alias(\"stars\")))\n# data = csv\ndf_ml.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----------+-----+\nuser_id|business_id|stars|\n+-------+-----------+-----+\n  21172|      14562|  0.0|\n  74272|      13614|  1.0|\n  67465|       6862|  1.0|\n  32162|      12636|  1.0|\n  32430|        852|  0.0|\n+-------+-----------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["df_ml.select(\"user_id\").distinct().count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[53]: 93921</div>"]}}],"execution_count":18},{"cell_type":"code","source":["df_ml.select(\"business_id\").distinct().count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[54]: 14766</div>"]}}],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["##Create a New Dataframe with columns \"user_id\", \"business_id\" and \"stars\"(Label)\n\nThese are the columns we used in building of ALS Model"],"metadata":{}},{"cell_type":"code","source":["data = df_ml.select(\"user_id\", \"business_id\", \"stars\")\nsplits = data.randomSplit([0.7, 0.3])\ntrain = splits[0].withColumnRenamed(\"stars\", \"label\") \ntest = splits[1].withColumnRenamed(\"stars\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()\nprint (\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Rows: 84023  Testing Rows: 35977\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["data.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----------+-----+\nuser_id|business_id|stars|\n+-------+-----------+-----+\n  21172|      14562|  0.0|\n  74272|      13614|  1.0|\n  67465|       6862|  1.0|\n  32162|      12636|  1.0|\n  32430|        852|  0.0|\n+-------+-----------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["### Build the Recommender\nIn ALS, user_id and business_id are to columns used for userCol, itemCol respectively.\n\n#### Latent Features\nWe can use the features to produce some sort of algorithm (**ALS**) to intelligently calculate stars(ratings) \n\nThe ALS class is an estimator, so you can use its **fit** method to traing a model, or you can include it in a pipeline. Rather than specifying a feature vector and as label, the ALS algorithm requries a numeric user ID, item ID, and stars."],"metadata":{}},{"cell_type":"code","source":["als = ALS(userCol=\"user_id\", itemCol=\"business_id\", ratingCol=\"label\")\n#als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"label\")\n#model = als.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["#### Add paramGrid and Validation"],"metadata":{}},{"cell_type":"code","source":["paramGrid = ParamGridBuilder() \\\n                    .addGrid(als.rank, [1, 5]) \\\n                    .addGrid(als.maxIter, [5, 10]) \\\n                    .addGrid(als.regParam, [0.3, 0.1]) \\\n                    .addGrid(als.alpha, [2.0,3.0]) \\\n                    .build()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["### To build a general model, _TrainValidationSplit_ is used by us as it is much faster than _CrossValidator_\nCrossValidator takes a very long time to run.\n\nYou can run a code with __CrossValidator__ instead as follows:\n```\ncv = CrossValidator(estimator=alsImplicit, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator())\n```"],"metadata":{}},{"cell_type":"code","source":["cv = TrainValidationSplit(estimator=als, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["train.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- user_id: integer (nullable = true)\n-- business_id: integer (nullable = true)\n-- label: double (nullable = true)\n\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["model = cv.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["test.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- user_id: integer (nullable = true)\n-- business_id: integer (nullable = true)\n-- trueLabel: double (nullable = true)\n\n</div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["### Test the Recommender\nNow that we've trained the recommender, lets see how accurately it predicts known stars in the test set."],"metadata":{}},{"cell_type":"code","source":["prediction = model.transform(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["prediction = model.transform(test)\n# Remove NaN values from prediction (due to SPARK-14489) [1]\nprediction = prediction.filter(prediction.prediction != float('nan'))\n\n# Round floats to whole numbers\nprediction = prediction.withColumn(\"prediction\", F.abs(F.round(prediction[\"prediction\"],0)))\n\n#prediction.join(df_ml, \"business_index\").select(\"user_index\", \"prediction\", \"trueLabel\").show(100, truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["prediction.show(20)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----------+---------+----------+\nuser_id|business_id|trueLabel|prediction|\n+-------+-----------+---------+----------+\n  66605|        148|      1.0|       1.0|\n  40410|        496|      1.0|       1.0|\n  74117|       1088|      1.0|       1.0|\n  28218|       1959|      1.0|       0.0|\n  90702|       2142|      1.0|       1.0|\n  83859|       5156|      1.0|       0.0|\n  51123|       5300|      1.0|       1.0|\n  26136|       5300|      1.0|       1.0|\n  28381|       5300|      1.0|       1.0|\n  69763|       5300|      1.0|       0.0|\n  27041|       5300|      1.0|       1.0|\n  53234|       5300|      1.0|       1.0|\n  42367|       5300|      1.0|       0.0|\n  54765|       5300|      1.0|       0.0|\n  59032|       5300|      1.0|       1.0|\n  80257|       5300|      1.0|       1.0|\n   3630|       5300|      1.0|       1.0|\n  55745|       5300|      1.0|       1.0|\n  71656|       5803|      1.0|       1.0|\n  78868|       5803|      1.0|       0.0|\n+-------+-----------+---------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["#### RegressionEvaluator\nCalculate RMSE using RegressionEvaluator.\n\n__NOTE:__ make sure to set [predictionCol=\"prediction\"]"],"metadata":{}},{"cell_type":"code","source":["# RegressionEvaluator: predictionCol=\"prediction\", metricName=\"rmse\"\nevaluator = RegressionEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(prediction)\nprint (\"Root Mean Square Error (RMSE):\", rmse)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Root Mean Square Error (RMSE): 0.6850465221305958\n</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["## Root Mean Square Error (RMSE): 0.6850465221305958"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":40}],"metadata":{"name":"oracle_project_als","notebookId":3350335684482617},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"markdown","source":["## CIS5560: PySpark Gradient Boosted Tree Regression in Databricks\n\n### by Team 4 (Uche, Raymond, Tofunmi and Sweta) edited on 05/15/2020\nTested in Runtime 6.5 (Spark 2.4.5/2.4.0 Scala 2.11) of Databricks CE"],"metadata":{}},{"cell_type":"markdown","source":["## Steps to download dataset and do some data engineering (Cleaning up dataset) before importing into databricks\n\n\nall dataset engineering were done in Jupyter Notebook before importing into databricks\n\ndataset link: https://www.kaggle.com/darshank2019/review#yelp_academic_dataset_review.csv\n\ndownload dataset and using a Jupyter Notebook(we used google colab), we accessed the dataset with total rows = 6685900\n\nwe took a slice of the full dataset of the first 1500000 rows and used that as our full dataset.\n\nwe removed the inverted commas and the letter \"b\" present in all rows (data cleaning)\n\nwe converted the alphanumeric values in the user_id, review_id, & business_id to numeric values\n\nwe tried to drop rows wit missing values and counted the total number of rows again and it was still 1500000.\n\nwe created a subset of our cleaned dataset named df_ml_csv with 120000 rows which we used for both Azure ML & Databricks\n\nNOTE: the .py & .ipynb files containing all codes used for data engineering and analysis is included in the total submission package and is availble in our github link"],"metadata":{}},{"cell_type":"markdown","source":["## For this project, we further normalised the user_id, review_id, and business_id columns of our df_ml dataset(subset with 120000 rows) \n\nNormalised dataset is named scaled_subset \n\nscaled_subset is imported into databricks and used for Gradient Boost classification model\n\nNOTE: Codes used for normalisation of the above listed columns are contained in thedata engineering and analysis .py & ipynb files uploaded to the github link"],"metadata":{}},{"cell_type":"markdown","source":["Import the scaled_subset.csv dataset"],"metadata":{}},{"cell_type":"markdown","source":["##Prepare the Data\nFirst, import the libraries you will need and prepare the training and test data:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\nfrom pyspark.ml.classification import GBTClassifier\n\nfrom pyspark.sql import functions as F\nimport pyspark.sql.functions as func\n\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml.linalg import Vectors, SparseVector\nimport re\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["## Create a DataFrame Schema, \nthat should be a Table schema"],"metadata":{}},{"cell_type":"code","source":["# DataFrame Schema, that should be a Table schema by Team 4 \ndf_mlSchema = StructType([\n  StructField(\"user_id\", IntegerType(), False),\n  StructField(\"text\", StringType(), False),\n  StructField(\"date\", TimestampType(), False),\n  StructField(\"review_id\", IntegerType(), False),\n  StructField(\"business_id\", IntegerType(), False),\n  StructField(\"funny\", IntegerType(), False),\n  StructField(\"cool\", IntegerType(), False),\n  StructField(\"useful\", IntegerType(), False),\n  StructField(\"stars\", IntegerType(), False),\n])"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["%fs ls /FileStore/tables/df_ml.csv"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/df_ml.csv</td><td>df_ml.csv</td><td>77730282</td></tr></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"code","source":["IS_SPARK_SUBMIT_CLI = True\nif IS_SPARK_SUBMIT_CLI:\n    sc = SparkContext.getOrCreate()\n    spark = SparkSession(sc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["##Load Dataset \n\nensure command line above: IS_SPARK_SUBMIT_CLI = False. Also remember to set it to 'True' before exporting"],"metadata":{}},{"cell_type":"markdown","source":["Read csv file from DBFS (Databricks File Systems)\n\n## follow the direction to read your table after upload it to Data at the left frame\nNOTE: See above for the data type - \n\nAfter df_ml_csv file is added to the data of the left frame, create a table using the UI, especially, \"Upload File\"\ntick header and infer schema before creating table"],"metadata":{}},{"cell_type":"code","source":["if IS_SPARK_SUBMIT_CLI:\n   df_ml = spark.read.csv('df_norm.csv', inferSchema=True, header=True)\nelse:\n    df_ml = spark.sql(\"SELECT * FROM scaled_subset_csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["df_ml.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------------------+--------------------+-------------------+--------------------+--------------------+-----+----+------+-----+\n_c0|           user_id|                text|               date|           review_id|         business_id|funny|cool|useful|stars|\n+---+------------------+--------------------+-------------------+--------------------+--------------------+-----+----+------+-----+\n  0|0.4875106473594548|Total bill for th...|2013-05-07 04:34:36| 0.06781723181026508|  0.7374873010497799|    1|   0|     6|  1.0|\n  1|0.7909071550255536|I *adore* Travis ...|2017-01-14 21:30:33| 0.10313419278493988| 0.04551303758889265|    0|   0|     0|  5.0|\n  2|0.5396614139693355|I have to say tha...|2016-11-09 20:09:03|0.024133534446120382|  0.3907213003725025|    0|   0|     3|  5.0|\n  3| 0.530291737649063|Went in for a lun...|2018-01-09 20:56:38|  0.4730956091300761|0.012258719945817812|    0|   0|     0|  5.0|\n  4| 0.554557069846678|Today was my seco...|2018-01-30 23:07:38| 0.12229268577238143|  0.5214358279715544|    0|   0|     7|  1.0|\n+---+------------------+--------------------+-------------------+--------------------+--------------------+-----+----+------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["##Create a New Dataframe with columns \"user_id\", \"review_id\", \"business_id\" and \"stars\"(label)\nThe label is the stars (stars > 2 = 1 (positive review) else: 0 (negative review)\n\nThese are the columns we used in building of Gradient Boost Classifier Model"],"metadata":{}},{"cell_type":"code","source":["data = df_ml.select(\"user_id\", \"review_id\", \"business_id\", ((col(\"stars\") > 2).cast(\"Double\").alias(\"label\")))\n\ndata.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+--------------------+--------------------+-----+\n           user_id|           review_id|         business_id|label|\n+------------------+--------------------+--------------------+-----+\n0.4875106473594548| 0.06781723181026508|  0.7374873010497799|  0.0|\n0.7909071550255536| 0.10313419278493988| 0.04551303758889265|  1.0|\n0.5396614139693355|0.024133534446120382|  0.3907213003725025|  1.0|\n 0.530291737649063|  0.4730956091300761|0.012258719945817812|  1.0|\n 0.554557069846678| 0.12229268577238143|  0.5214358279715544|  0.0|\n+------------------+--------------------+--------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["splits = data.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()\nprint (\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Rows: 83694  Testing Rows: 36306\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["### Build the Recommender\n user_id, review_id and business_id are columns we used to build the Gradient Boost Classifier Model.\n\n#### Latent Features\nWe can use the features to produce some sort of algorithm (**GBTRegression**) to intelligently calculate stars(ratings) \n\nThe GBT class is an estimator, so you can use its **fit** method to traing a model, or you can include it in a pipeline. Rather than specifying a feature vector and as label, the GBT algorithm requries user_id, review_id and business_id columns are Normalized\nNOTE: all columns are normalized in python jupyter notebook before dataframe was imported"],"metadata":{}},{"cell_type":"code","source":["gbtassembler = VectorAssembler(inputCols=[\"user_id\", \"review_id\", \"business_id\"], outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["gbtp = Pipeline(stages=[gbtassembler, gbt])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["#### Add paramGrid and Validation"],"metadata":{}},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(gbt.maxDepth,[2,3,4])\n             .addGrid(gbt.maxBins, [49, 52, 55])\n             .addGrid(gbt.minInfoGain,[0.0, 0.1, 0.2, 0.3])\n             .addGrid(gbt.stepSize,[0.05, 0.1, 0.2, 0.4])\n         \n             .build())\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["### To build a general model, _TrainValidationSplit_ is used by us as it is much faster than _CrossValidator_\nCrossValidator takes a very long time to run."],"metadata":{}},{"cell_type":"code","source":["gbt_tvs = TrainValidationSplit(estimator=gbtp, evaluator=MulticlassClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n\ngbtModel = gbt_tvs.fit(train)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["### Test the Recommender\nNow that we've trained the recommender, lets see how accurately it predicts known stars in the test set."],"metadata":{}},{"cell_type":"code","source":["prediction = gbtModel.transform(test)\npredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\npredicted.show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+----------+---------+\n            features|prediction|trueLabel|\n+--------------------+----------+---------+\n[1.27768313458262...|       1.0|      0.0|\n[5.85604770017035...|       1.0|      1.0|\n[8.62436115843270...|       1.0|      0.0|\n[0.00102214650766...|       1.0|      0.0|\n[0.00121379897785...|       1.0|      0.0|\n[0.00122444633730...|       1.0|      1.0|\n[0.00143739352640...|       1.0|      1.0|\n[0.00158645655877...|       1.0|      1.0|\n[0.00166098807495...|       1.0|      1.0|\n[0.00190587734241...|       1.0|      0.0|\n+--------------------+----------+---------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["##TP, FP, TN, and FN all calculated\nPrecision and recall also calculated"],"metadata":{}},{"cell_type":"code","source":["tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\nfp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\ntn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\nfn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\nmetrics = spark.createDataFrame([\n      (\"TP\", tp),\n      (\"FP\", fp),\n      (\"TN\", tn),\n      (\"FN\", fn),\n      (\"Precision\", tp / (tp + fp)),\n      (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\nmetrics.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+------------------+\n   metric|             value|\n+---------+------------------+\n       TP|           28083.0|\n       FP|            8204.0|\n       TN|               7.0|\n       FN|              12.0|\nPrecision|0.7739135227491939|\n   Recall| 0.999572877736252|\n+---------+------------------+\n\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["## AUC is calculated"],"metadata":{}},{"cell_type":"code","source":["gbt_evaluator =  MulticlassClassificationEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\")\ngbt_auc = gbt_evaluator.evaluate(prediction)\n\nprint(\"AUC for Gradient Boost Classifier = \", gbt_auc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">AUC for Gradient Boost Classifier =  0.675471596680073\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["## AUC for Gradient Boost Classifier =  0.675471596680073"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":33}],"metadata":{"name":"Project_GradientBoostClassification","notebookId":1973154391279075},"nbformat":4,"nbformat_minor":0}
